from vector_store import vector_db
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_upstage import ChatUpstage

# LLM ë° íŒŒì„œ ì´ˆê¸°í™”
llm = ChatUpstage(model="solar-1-mini-chat", api_key="up_4CGSrG6veWVgB4OItylUF0q3FACj0")
output_parser = StrOutputParser()

prompt_template = PromptTemplate.from_template("""
ë‹¹ì‹ ì€ ìë™ì°¨ ê´‘ê³  ì „ë¬¸ ë§ˆì¼€í„°ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ ìœ ì‚¬í•œ ì°¨ëŸ‰ ì •ë³´ì…ë‹ˆë‹¤:

{context}

ì´ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìì˜ ìš”ì²­ "{query}"ì— ë§ëŠ”
ë§¤ë ¥ì ì´ê³  ì„¸ë ¨ëœ ì¤‘ê³ ì°¨ ê´‘ê³  ë¬¸êµ¬ë¥¼ 10ë¬¸ì¥ ì •ë„ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

[ìš”êµ¬ ì¡°ê±´]
- ìì—°ìŠ¤ëŸ½ê³  ê°ì„±ì ì¸ í†¤
- ê°•ì¡° í¬ì¸íŠ¸ê°€ ëª…í™•í•  ê²ƒ
- ì¡´ëŒ“ë§ ì‚¬ìš©
""")

# RAG ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def get_rag_response(query: str) -> str:
    try:
        docs = vector_db.similarity_search(query, k=3)
        context = "\n".join([doc.page_content for doc in docs])
        prompt = prompt_template.format_prompt(context=context, query=query).to_string()

        print("ğŸ§ª ìƒì„±ëœ í”„ë¡¬í”„íŠ¸:\n", prompt)

        response = llm.invoke(prompt)
        print("ğŸ“¤ LLM ì‘ë‹µ:", response)

        return output_parser.invoke(response).strip()

    except Exception as e:
        print(f"âŒ RAG ì˜¤ë¥˜ (query: {query}):", e)
        return "ğŸš¨ ê´‘ê³  ë¬¸êµ¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
