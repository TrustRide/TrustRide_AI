from fastapi import APIRouter
from pydantic import BaseModel
from langchain_upstage import ChatUpstage, UpstageEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

from dotenv import load_dotenv
load_dotenv()

router = APIRouter(
    prefix="/terms",
    tags=["term"],
)

class Question(BaseModel):
    query: str


# ì´ˆê¸° ì„¸íŒ… (í•œë²ˆë§Œ ë¡œë”©)
loader = TextLoader("./router/Trust_Ride_Terms.txt", encoding="utf-8")
docs = loader.load()

splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
splits = splitter.split_documents(docs)

embeddings = UpstageEmbeddings(model="solar-embedding-1-large")
vector_store = Chroma(embedding_function=embeddings)
vector_store.add_documents(splits)
retriever = vector_store.as_retriever() #ë²¡í„° dbì—ì„œ ë¬¸ì¥ì¢€ ì°¾ì•„ì¤˜..

llm = ChatUpstage(model="solar-pro")
prompt_template = PromptTemplate.from_template(
    '''
    ì•„ë˜ì˜ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ì í•©í•œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ë§Œì•½ ê´€ë ¨ ì •ë³´ê°€ ì—†ë‹¤ë©´ 'ì£„ì†¡í•´ìš”, í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ì—†ì–´ìš” ğŸ˜¢'ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”.
    ---
    ì§ˆë¬¸: {question}
    ---
    ì»¨í…ìŠ¤íŠ¸: {context}
    '''
)
chain = prompt_template | llm | StrOutputParser()


@router.post("/ask")
async def ask_question(data: Question):
    query = data.query
    context = retriever.invoke(query)
    context_docs = context[0].page_content if context else ""
    result = chain.invoke({"question": query, "context": context_docs})
    return {"answer": result}