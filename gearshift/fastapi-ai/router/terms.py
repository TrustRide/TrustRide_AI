from fastapi import APIRouter
from pydantic import BaseModel
from langchain_upstage import ChatUpstage, UpstageEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
import os

load_dotenv()

router = APIRouter(
    prefix="/terms",
    tags=["term"],
)

class Question(BaseModel):
    query: str

# ì´ˆê¸° ì„¸íŒ…
loader = TextLoader("./router/Trust_Ride_Terms.txt", encoding="utf-8")
docs = loader.load()

splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
splits = splitter.split_documents(docs)

# âœ… API í‚¤ ì§ì ‘ ì „ë‹¬
embeddings = UpstageEmbeddings(
    model="solar-embedding-1-large",
    api_key="up_4CGSrG6veWVgB4OItylUF0q3FACj0"
)

# ì„ë² ë”©ëœ ë¬¸ì„œë¡œ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (ë©”ëª¨ë¦¬ ê¸°ë°˜)
vector_store = Chroma(embedding_function=embeddings)
vector_store.add_documents(splits)

retriever = vector_store.as_retriever()

# âœ… API í‚¤ ì§ì ‘ ì „ë‹¬
llm = ChatUpstage(
    model="solar-pro",
    api_key="up_4CGSrG6veWVgB4OItylUF0q3FACj0"
)

prompt_template = PromptTemplate.from_template(
    '''
    ì•„ë˜ì˜ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ì í•©í•œ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ë§Œì•½ ê´€ë ¨ ì •ë³´ê°€ ì—†ë‹¤ë©´ 'ì£„ì†¡í•´ìš”, í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ì—†ì–´ìš” ğŸ˜¢'ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”.
    ---
    ì§ˆë¬¸: {question}
    ---
    ì»¨í…ìŠ¤íŠ¸: {context}
    '''
)
chain = prompt_template | llm | StrOutputParser()

@router.post("/ask")
async def ask_question(data: Question):
    query = data.query
    context = retriever.invoke(query)
    context_docs = context[0].page_content if context else ""
    result = chain.invoke({"question": query, "context": context_docs})
    return {"answer": result}
