from fastapi import APIRouter
from typing import Optional
from pydantic import BaseModel
from . import extractor, rag, terms
from langchain_core.messages import HumanMessage
from .agent_chain import agent_executor
import logging

logger = logging.getLogger("chat_logger")
logging.basicConfig(level=logging.INFO)

router = APIRouter(
    prefix="/chat",
    tags=["chat"],
)

class UserQuery(BaseModel):
    message: str


### ì‹œì„¸ ###
class ParsedCarInfo(BaseModel):
    model: str
    fuel_type: Optional[str] = ""
    offered_price: str
    trim: Optional[str] = ""           

@router.post("/price")
def chat(query: UserQuery):
    parsed = extractor.extract_info_with_llm(query.message)
    answer = rag.get_rag_response(parsed)
    return {
        "parsed_info": parsed,
        "answer": answer
    }


### ì•½ê´€ ###
@router.post("/term")
async def ask_question(query: UserQuery):
    query = query.message
    context = terms.retriever.invoke(query)
    context_docs = context[0].page_content if context else ""
    result = terms.chain.invoke({"question": query, "context": context_docs})
    return {"answer": result}


### í†µí•© ###
@router.post("/integrate")
async def integrated_chat(query: UserQuery):
    result = await agent_executor.ainvoke({"messages": [HumanMessage(content=query.message)]})

    # LLMì´ toolì„ ì“°ì§€ ì•Šê³  LLMì˜ ìƒê°ìœ¼ë¡œ ë‹µë³€í–ˆëŠ”ì§€ ì²´í¬
    if isinstance(result, str):
        logger.error('LLMì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë§ˆìŒëŒ€ë¡œ ë‹µë³€')
        return {"answer": "ì£„ì†¡í•´ìš”, í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ì—†ì–´ìš” ğŸ˜¢"}

    # tool ì‹¤í–‰ ê²°ê³¼ë§Œ êº¼ë‚´ê¸°
    tool_outputs = result.get("intermediate_steps", []) #ì‹¤í–‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ [] ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‘ë‹µ

    for step in tool_outputs:
        if isinstance(step, tuple):
            _, tool_output = step
            return {"answer": tool_output}

    # tool ì‹¤í–‰ ê²°ê³¼ê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¼ë©´
    return {"answer": "ì£„ì†¡í•´ìš”, í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ì—†ì–´ìš” ğŸ˜¢"}