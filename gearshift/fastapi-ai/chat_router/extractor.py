from langchain_upstage import ChatUpstage
from langchain_core.prompts import PromptTemplate
import json
from . import settings

# Upstage LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
llm = ChatUpstage(api_key=settings.LLM_API_KEY, model="solar-1-mini-chat")


# ì°¨ëŸ‰ ì •ë³´ ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
extract_prompt = PromptTemplate.from_template("""
ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ì°¨ëŸ‰ì˜ ëª¨ë¸ëª…, ì—°ë£Œ, íŠ¸ë¦¼, ì œì‹œ ê°€ê²©(ë§Œì›)ì„ ì¶”ì¶œí•´ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ë°˜í™˜í•´ì¤˜.
í˜•ì‹: {{ "model": "ëª¨ë¸ëª…", "fuel_type": "ì—°ë£Œ", "trim": "íŠ¸ë¦¼", "offered_price": 0000 }}

ì˜ˆì‹œ:
ë¬¸ì¥: "ì˜ë‚˜íƒ€ ë‰´ ë¼ì´ì¦ˆ ê°€ì†”ë¦° 2.0 ìŠ¤ë§ˆíŠ¸ë¥¼ 1,800ë§Œì›ì— ì‚¬ë ¤ëŠ”ë° ê´œì°®ì•„?"
ê²°ê³¼: {{ "model": "ì˜ë‚˜íƒ€ ë‰´ ë¼ì´ì¦ˆ", "fuel_type": "ê°€ì†”ë¦°", "trim": "2.0 ìŠ¤ë§ˆíŠ¸", "offered_price": 1800 }}

ë¬¸ì¥: "{message}"
""")

# LLM ì‘ë‹µì„ ìˆ˜ë™ìœ¼ë¡œ JSONìœ¼ë¡œ íŒŒì‹±í•˜ëŠ” í´ë˜ìŠ¤ ì •ì˜
class ManualJsonParser:
    def invoke(self, text: str):
        try:
             # ë¬¸ìì—´ì„ JSONìœ¼ë¡œ ë³€í™˜ ì‹œë„
            return json.loads(text)
        except Exception:
            # ì‹¤íŒ¨í•˜ë©´ ì—ëŸ¬ ë©”ì‹œì§€ì™€ í•¨ê»˜ ì˜ˆì™¸ ë°œìƒ
            raise ValueError("ğŸš« JSON íŒŒì‹± ì‹¤íŒ¨: ì‘ë‹µ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\në‚´ìš©:\n" + text)

# íŒŒì„œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
parser = ManualJsonParser()

# ì‚¬ìš©ìì˜ ìì—°ì–´ ë©”ì‹œì§€ë¥¼ ë°›ì•„ì„œ ì°¨ëŸ‰ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def extract_info_with_llm(message: str):

    # ì…ë ¥ ë©”ì‹œì§€ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì‚½ì…
    prompt = extract_prompt.format(message=message)

    # LLMì—ê²Œ í”„ë¡¬í”„íŠ¸ ì „ë‹¬í•˜ì—¬ ì‘ë‹µ ë°›ê¸°
    raw_output = llm.invoke(prompt)

     # LLM ì‘ë‹µì—ì„œ contentë§Œ ì¶”ì¶œí•˜ì—¬ JSONìœ¼ë¡œ íŒŒì‹± 
    return parser.invoke(raw_output.content)  
